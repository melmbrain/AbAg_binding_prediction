C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan
C:\Users\401-24\Desktop\AbAg_binding_prediction\scripts\integrate_all_databases.py:359: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  df[col] = np.nan

================================================================================
UNIFIED DATABASE INTEGRATION PIPELINE
================================================================================

================================================================================
LOADING EXISTING DATASET
================================================================================

Loading from: C:/Users/401-24/Desktop/Docking prediction/data/processed/phase6/final_205k_dataset.csv
  Loaded 204986 samples
  Columns: 153

================================================================================
Existing Dataset Statistics
================================================================================
Total samples: 204986
Mean pKd: 7.57
Std pKd: 2.09
Range: [-4.10, 15.70]

Distribution by affinity range:
        bin     range  count  percentage      mean      std       min       max
  very_weak   0.0-5.0   3778    1.843053  1.052028 1.498265  0.000112  4.995679
       weak   5.0-7.0  66114   32.252934  6.054801 0.206935  5.000000  6.999630
   moderate   7.0-9.0  71789   35.021416  8.306565 0.525031  7.000000  8.999980
     strong  9.0-11.0  58567   28.571219  9.417657 0.217566  9.000000 10.999984
very_strong 11.0-16.0    240    0.117081 11.644207 0.801783 11.000000 15.698970
================================================================================


================================================================================
DETECTING DOWNLOADED DATABASES
================================================================================

OK AbBiBench: abbibench_processed.csv

================================================================================
LOADING EXTERNAL DATABASES
================================================================================

Loading abbibench...
  Raw data: 185718 samples
  Processed: 185718 samples

================================================================================
CHECKING FOR DUPLICATES
================================================================================

Existing dataset: 204986 unique PDB codes

WARNING abbibench: No pdb_code column

--------------------------------------------------------------------------------
Cross-database duplicates:
--------------------------------------------------------------------------------

================================================================================
REMOVING DUPLICATES
================================================================================

WARNING abbibench: No pdb_code column, keeping all

================================================================================
AFFINITY DISTRIBUTION ANALYSIS
================================================================================

Existing Dataset:

================================================================================
Existing Statistics
================================================================================
Total samples: 204986
Mean pKd: 7.57
Std pKd: 2.09
Range: [-4.10, 15.70]

Distribution by affinity range:
        bin     range  count  percentage      mean      std       min       max
  very_weak   0.0-5.0   3778    1.843053  1.052028 1.498265  0.000112  4.995679
       weak   5.0-7.0  66114   32.252934  6.054801 0.206935  5.000000  6.999630
   moderate   7.0-9.0  71789   35.021416  8.306565 0.525031  7.000000  8.999980
     strong  9.0-11.0  58567   28.571219  9.417657 0.217566  9.000000 10.999984
very_strong 11.0-16.0    240    0.117081 11.644207 0.801783 11.000000 15.698970
================================================================================


abbibench:

================================================================================
abbibench Statistics
================================================================================
Total samples: 185718
Mean pKd: 7.55
Std pKd: 2.17
Range: [-4.10, 13.22]

Distribution by affinity range:
        bin     range  count  percentage      mean      std       min       max
  very_weak   0.0-5.0   3452    1.858732  0.744085 1.151156  0.000112  4.993869
       weak   5.0-7.0  62675   33.747402  6.033731 0.154479  5.009166  6.999590
   moderate   7.0-9.0  57286   30.845691  8.381717 0.492953  7.000000  8.999980
     strong  9.0-11.0  57706   31.071840  9.413616 0.206621  9.000021 10.999984
very_strong 11.0-16.0    101    0.054384 11.317280 0.342840 11.011759 13.218016
================================================================================


================================================================================
MERGING ALL DATASETS
================================================================================

================================================================================
PREPARING FOR INTEGRATION
================================================================================

Feature columns in existing dataset: 150

Preparing abbibench...
  WARNING Missing columns: ['pdb_code']

OK Prepared 0 datasets for integration

WARNING No external datasets to merge

================================================================================
SUMMARY REPORT
================================================================================

================================================================================
AFFINITY DISTRIBUTION ANALYSIS
================================================================================

Existing Dataset:

================================================================================
Existing Statistics
================================================================================
Total samples: 204986
Mean pKd: 7.57
Std pKd: 2.09
Range: [-4.10, 15.70]

Distribution by affinity range:
        bin     range  count  percentage      mean      std       min       max
  very_weak   0.0-5.0   3778    1.843053  1.052028 1.498265  0.000112  4.995679
       weak   5.0-7.0  66114   32.252934  6.054801 0.206935  5.000000  6.999630
   moderate   7.0-9.0  71789   35.021416  8.306565 0.525031  7.000000  8.999980
     strong  9.0-11.0  58567   28.571219  9.417657 0.217566  9.000000 10.999984
very_strong 11.0-16.0    240    0.117081 11.644207 0.801783 11.000000 15.698970
================================================================================


abbibench:

================================================================================
abbibench Statistics
================================================================================
Total samples: 185718
Mean pKd: 7.55
Std pKd: 2.17
Range: [-4.10, 13.22]

Distribution by affinity range:
        bin     range  count  percentage      mean      std       min       max
  very_weak   0.0-5.0   3452    1.858732  0.744085 1.151156  0.000112  4.993869
       weak   5.0-7.0  62675   33.747402  6.033731 0.154479  5.009166  6.999590
   moderate   7.0-9.0  57286   30.845691  8.381717 0.492953  7.000000  8.999980
     strong  9.0-11.0  57706   31.071840  9.413616 0.206621  9.000021 10.999984
very_strong 11.0-16.0    101    0.054384 11.317280 0.342840 11.011759 13.218016
================================================================================

================================================================================
DATABASE INTEGRATION SUMMARY
================================================================================

## Datasets Loaded:

- Existing: 204986 samples
- abbibench: 185718 samples

## Affinity Distribution (after removing duplicates):

| Bin | Existing | AbBiBench | SAAINT | PDBbind |
|-----|----------|-----------|--------|---------|
| very_weak    |   3778 ( 1.8%) |   3452 ( 1.9%) | - | - |
| weak         |  66114 (32.3%) |  62675 (33.7%) | - | - |
| moderate     |  71789 (35.0%) |  57286 (30.8%) | - | - |
| strong       |  58567 (28.6%) |  57706 (31.1%) | - | - |
| very_strong  |    240 ( 0.1%) |    101 ( 0.1%) | - | - |

## Next Steps:

1. OK Data downloaded and integrated
2. WARNING ESM2 embeddings needed for new sequences
3. WARNING PCA transformation required
4. Re-train model with augmented dataset

## ESM2 Embedding Generation:

The new samples have NaN for ESM2 PCA features.
You need to:
  a. Extract antibody/antigen sequences
  b. Generate ESM2 embeddings
  c. Apply existing PCA transformation
  d. Fill in feature columns

OK Report saved to: external_data\integration_report.txt

================================================================================
INTEGRATION COMPLETE!
================================================================================

OK Integrated 1 external databases
OK Total samples: 204986
OK Saved to: external_data/merged_with_abbibench.csv
OK Report: external_data/integration_report.txt

WARNING IMPORTANT:
New samples need ESM2 embeddings!
See report for next steps.

OK Done!
