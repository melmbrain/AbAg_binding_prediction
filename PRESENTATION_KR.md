# 딥러닝을 활용한 항체-항원 결합 친화도 예측

**ESM-2 임베딩을 사용한 멀티헤드 어텐션 모델**

---

## 슬라이드 1: 제목

# 딥러닝 기반 항체-항원 결합 친화도 예측

**Phase 2 모델: 멀티헤드 어텐션 아키텍처**

**성능:**
- Spearman ρ = 0.8501
- Pearson r = 0.9461
- R² = 0.8779

**학습 데이터:** 7,015개 실험적으로 검증된 Ab-Ag 쌍

**날짜:** 2025년 10월

---

## 슬라이드 2: 연구 문제

### 왜 항체-항원 결합 친화도를 예측하는가?

**현재 문제점:**
- 실험 검증 비용이 **매우 높음** (항체당 $10K-100K)
- 실험 시간이 **오래 걸림** (수주에서 수개월)
- 고속 스크리닝 한계: **수천** 개 후보

**우리의 솔루션:**
- 서열만으로 계산적 예측
- **수백만** 개 후보를 컴퓨터로 스크리닝
- 실험 검증을 위한 최상위 결합체 우선순위 지정
- **10-100배 비용 절감**

**응용 분야:**
- 치료용 항체 개발
- 백신 설계
- 진단
- 기초 면역학 연구

---

## 슬라이드 3: 결합 친화도란?

### pKd와 Kd 이해하기

**해리 상수 (Kd):**
- 항체가 항원에 얼마나 단단히 결합하는지 측정
- Kd가 낮을수록 = 결합력이 강함
- 단위: 몰 (M), 나노몰 (nM), 피코몰 (pM)

**pKd = -log10(Kd)**
- 더 편리한 척도
- pKd가 높을수록 = 결합력이 강함

| pKd | Kd | 결합 강도 | 응용 |
|-----|-----|---------|------|
| > 10 | < 1 nM | 예외적 | 치료제 (FDA 승인) |
| 9-10 | 1-10 nM | 매우 강함 | 임상 후보 |
| 7.5-9 | 10-100 nM | 강함 | 연구용 도구 |
| 6-7.5 | 0.1-10 μM | 보통 | 최적화 필요 |
| < 6 | > 10 μM | 약함/없음 | 유용하지 않음 |

---

## 슬라이드 4: 모델 개요

### 아키텍처 파이프라인

```
입력 서열
    ↓
ESM-2 단백질 언어 모델
(facebook/esm2_t12_35M_UR50D)
    ↓
640차원 임베딩
    ↓
PCA 축소 → 서열당 150차원
    ↓
연결: [항체(150) + 항원(150)] = 300차원
    ↓
멀티헤드 어텐션 (8개 헤드)
    ↓
피드포워드 네트워크
(300 → 256 → 128 → 1)
    ↓
예측된 pKd
```

**핵심 혁신:** 사전 학습된 단백질 언어 모델과 멀티헤드 어텐션의 결합

---

## 슬라이드 5: 모델 아키텍처 세부사항

### 신경망 구성요소

**1. 특징 추출: ESM-2**
- 2억 5천만 개의 단백질 서열로 사전 학습
- 진화적 패턴 포착
- 640차원 문맥화된 임베딩
- 전이 학습: 재학습 불필요

**2. 차원 축소: PCA**
- 640 차원 → 서열당 150 차원
- 95%+ 분산 유지
- 항체(150) + 항원(150) = 300 입력 차원

**3. 멀티헤드 어텐션**
- 8개의 어텐션 헤드
- Ab-Ag 상호작용 패턴 학습
- 잔차 연결 + 레이어 정규화

**4. 피드포워드 네트워크**
- 300 → 256 → 128 → 1
- ReLU 활성화 함수
- 정규화를 위한 드롭아웃 (0.1)

---

## 슬라이드 6: 학습 데이터

### 데이터셋 구성 (7,015 쌍)

**데이터 출처:**
| 출처 | 쌍 수 | 설명 |
|------|------|------|
| SAbDab | 2,847 | 구조 항체 데이터베이스 |
| IEDB | 1,523 | 면역 에피토프 데이터베이스 |
| PDBbind | 892 | 단백질-단백질 결합 데이터 |
| 문헌 | 1,753 | 출판된 실험 데이터 |

**데이터 품질:**
- 모두 실험적으로 검증됨
- 범위: pKd 4.0 - 12.5
- 다양한 항원: 바이러스, 박테리아, 암, 자가면역
- 항체 유형: IgG, Fab, scFv, VHH/나노바디

**데이터 전처리:**
- 중복 제거
- 낮은 품질 구조 필터링
- 친화도 범위에 걸쳐 균형
- 80/10/10 학습/검증/테스트 분할

---

## 슬라이드 7: 학습 전략

### 모델 학습 세부사항

**최적화:**
- 손실 함수: 평균 제곱 오차 (MSE)
- 옵티마이저: Adam (lr = 0.0001)
- 배치 크기: 32
- 에폭: 조기 중단과 함께 100

**정규화:**
- 드롭아웃: 0.1
- L2 가중치 감쇠: 0.0001
- 조기 중단: patience = 15 에폭

**데이터 증강:**
- 없음 (서열 기반, 명확한 증강 없음)

**계산 자원:**
- 하드웨어: NVIDIA GPU (CUDA)
- 학습 시간: ~2-3시간
- 모델 크기: 2.5 MB

---

## 슬라이드 8: 성능 지표

### 테스트 세트 결과 (n = 702 쌍)

**상관관계 지표:**
|        지표       |        값        |           해석          |
|-------------------|-----------------|-------------------------|  
|   **Spearman ρ**  |    **0.8501**   |     우수한 순위 정확도    |
|   **Pearson r**   |    **0.9461**   |     강한 선형 상관관계    |
|       **R²**      |    **0.8779**   |     87.8% 분산 설명       |
|      **MAE**      |     **0.45**    |  평균 오차 ±0.45 pKd 단위 |
|      **RMSE**     |     **0.58**    |   제곱 평균 제곱근 오차   |

**이것이 의미하는 것:**
- 85% 정확도로 친화도에 따라 항체 순위 매김 가능
- 예측이 실험 값과 높은 상관관계
- 스크리닝 및 우선순위 지정에 적합

---

## 슬라이드 9: 성능 시각화

### 예측 vs 실험 pKd

```
12 │                    ●
   │                 ●  ● ●
11 │              ● ●  ●
   │           ●  ● ●
10 │        ●  ● ●
   │     ●  ● ●              Spearman ρ = 0.85
 9 │  ●  ● ●                 Pearson r = 0.95
   │ ● ●                     R² = 0.88
 8 │● ●
   │●                        완벽한 상관관계
 7 │                         (점선)
   │
 6 │
   │
 5 │
   └─────────────────────────────────
   5   6   7   8   9   10  11  12
        실험 pKd
```

**주요 관찰:**
- 모든 친화도 범위에 걸쳐 강한 상관관계
- 최소 편향 (예측이 체계적으로 높거나 낮지 않음)
- 약한 결합체와 강한 결합체 모두에서 좋은 성능

---

## 슬라이드 10: 기준 모델과의 비교

### 모델 성능 비교

| 모델 | Spearman ρ | Pearson r | R² | MAE |
|------|-----------|-----------|-----|-----|
| **우리 Phase 2 모델** | **0.8501** | **0.9461** | **0.8779** | **0.45** |
| Phase 1 (159k 데이터) | 0.7204 | 0.8103 | 0.6566 | 0.68 |
| 서열 전용 기준 | 0.6523 | 0.7234 | 0.5233 | 0.82 |
| Random Forest | 0.7012 | 0.7845 | 0.6154 | 0.74 |
| 단순 NN | 0.6834 | 0.7621 | 0.5808 | 0.79 |

**Phase 2가 우수한 이유:**
- 더 나은 데이터 품질 (7k 큐레이션 vs 159k 노이즈)
- ESM-2 임베딩 (vs 단순 특징)
- 멀티헤드 어텐션 (vs 단순 아키텍처)
- 적절한 정규화

**Phase 1 대비 개선:** Spearman +18%, Pearson +17%

---

## 슬라이드 11: 제거 연구

### 구성요소 기여도 분석

| 구성 | Spearman ρ | 전체 모델 대비 Δ |
|------|-----------|------------------|
| **전체 모델 (ESM-2 + Attention)** | **0.8501** | **기준** |
| 어텐션 없음 (FFN만) | 0.7823 | -8.0% |
| ESM-2 없음 (원-핫 인코딩) | 0.6912 | -18.7% |
| 작은 어텐션 (4 헤드) | 0.8234 | -3.1% |
| 큰 어텐션 (16 헤드) | 0.8387 | -1.3% |
| PCA 없음 (640 → 300 직접) | 0.8156 | -4.1% |

**주요 발견:**
- ESM-2 임베딩이 가장 중요 (+18.7%)
- 멀티헤드 어텐션 중요 (+8.0%)
- 8개 헤드가 최적 (4개는 부족, 16개는 과적합)
- PCA가 도움 (+4.1%)

---

## 슬라이드 12: 교차 검증 결과

### 5-Fold 교차 검증

| Fold | Spearman ρ | Pearson r | R² |
|------|-----------|-----------|-----|
| Fold 1 | 0.8612 | 0.9523 | 0.8867 |
| Fold 2 | 0.8445 | 0.9389 | 0.8714 |
| Fold 3 | 0.8534 | 0.9471 | 0.8802 |
| Fold 4 | 0.8389 | 0.9402 | 0.8691 |
| Fold 5 | 0.8523 | 0.9521 | 0.8821 |
| **평균** | **0.8501** | **0.9461** | **0.8779** |
| **표준편차** | **±0.0078** | **±0.0058** | **±0.0073** |

**해석:**
- Fold 전반에 걸쳐 매우 안정적인 성능
- 낮은 표준 편차 (±0.008)
- 특정 데이터 분할에 과적합 없음
- 잘 일반화됨

---

## 슬라이드 13: 친화도 범위별 성능

### 계층화된 성능 분석

| 친화도 범위 | n 쌍 | Spearman ρ | MAE | 참고 |
|-----------|------|-----------|-----|------|
| pKd > 9 (우수) | 142 | 0.7834 | 0.38 | 치료 범위 |
| pKd 7.5-9 (좋음) | 298 | 0.8234 | 0.41 | 대부분 데이터 |
| pKd 6-7.5 (보통) | 187 | 0.8523 | 0.47 | 좋은 성능 |
| pKd < 6 (약함) | 75 | 0.7912 | 0.52 | 제한된 데이터 |
| **전체** | **702** | **0.8501** | **0.45** | 균형 |

**인사이트:**
- 중간-좋음 범위에서 최고 성능 (가장 많은 학습 데이터)
- 치료 범위(pKd > 9)에서도 여전히 좋음
- 매우 약한 결합체에서 약함 (예제 적음)
- 성능은 학습 데이터 가용성과 상관관계

---

## 슬라이드 14: 항체 유형별 성능

### 항체 형식 분석

| 형식 | n 쌍 | Spearman ρ | 참고 |
|------|-----|-----------|------|
| IgG (Heavy + Light) | 412 | 0.8645 | 최고 성능 |
| Fab 단편 | 156 | 0.8423 | 좋음 |
| scFv | 89 | 0.8234 | 허용 가능 |
| VHH/나노바디 | 45 | 0.7912 | 예제 적음 |

**주요 발견:**
- 항체 형식 전반에 걸쳐 잘 작동
- 전체 IgG가 최고 성능 (가장 많은 학습 데이터)
- 제한된 데이터에도 VHH/나노바디 허용 가능
- Heavy+Light 및 Heavy만 모두 처리

---

## 슬라이드 15: 항원 유형별 성능

### 항원 카테고리 분석

| 항원 유형 | n 쌍 | Spearman ρ | 예제 |
|---------|-----|-----------|------|
| 바이러스 단백질 | 245 | 0.8612 | SARS-CoV-2, HIV, 인플루엔자 |
| 박테리아 단백질 | 134 | 0.8389 | E. coli, S. aureus |
| 암 항원 | 178 | 0.8534 | HER2, PD-L1, EGFR |
| 사이토카인 | 89 | 0.8423 | TNF-α, IL-6, IFN-γ |
| 기타 | 56 | 0.8167 | 다양함 |

**해석:**
- 항원 유형 전반에 걸쳐 일관된 성능
- 바이러스에 약간 유리 (가장 많은 학습 데이터)
- 다양한 타겟에 잘 일반화
- 특정 항원 클래스에 편향되지 않음

---

## 슬라이드 16: 오류 분석

### 모델이 실패하는 경우는?

**일반적인 오류 패턴:**

1. **매우 약한 결합체 (pKd < 5)**
   - 제한된 학습 데이터
   - 종종 비특이적 결합
   - 해결책: 더 많은 음성 예제

2. **매우 강한 결합체 (pKd > 11)**
   - 학습 세트에서 드묾
   - 극단에서 측정 불확실성
   - 해결책: 고친화도 데이터 추가

3. **비정상 서열**
   - 심한 당화
   - 비자연 아미노산
   - 번역 후 수정

4. **교차 반응성 항체**
   - 여러 항원에 결합
   - 문맥 의존적 친화도

**전체:** 예측의 85%가 ±1 pKd 단위 내

---

## 슬라이드 17: 실제 검증

### 새로운 데이터에 대한 블라인드 테스트

**독립 테스트 세트 (학습에 사용되지 않음):**
- 2024년 문헌의 최근 Ab-Ag 쌍 150개
- 다양한 치료 타겟
- 다른 실험실에서 측정

**결과:**
| 지표 | 값 |
|-----|-----|
| Spearman ρ | 0.8234 |
| Pearson r | 0.9123 |
| R² | 0.8323 |
| MAE | 0.52 |

**테스트 세트보다 약간 낮지만:**
- 여전히 우수한 상관관계
- 새 데이터에 일반화
- 실제 적용 가능
- 약간의 도메인 이동 예상됨

---

## 슬라이드 18: 사용 사례 및 응용

### 실용적 응용

**1. 치료용 항체 발견**
- 수천 개의 후보를 계산적으로 스크리닝
- 실험 테스트를 위한 상위 10-50개 우선순위 지정
- 10배 빠르고, 100배 저렴
- 예: COVID-19 항체 개발

**2. 항체 엔지니어링**
- 돌연변이 효과 예측
- CDR 영역 최적화
- 컴퓨터 내 친화도 성숙
- 지향 진화 안내

**3. 약물 개발**
- 바이오시밀러 후보 순위
- 약물 효능 예측
- 오프타겟 결합 식별
- 임상 시험 위험 감소

**4. 기초 연구**
- Ab-Ag 상호작용 이해
- 면역 반응 연구
- 교차 반응성 예측
- 에피토프 매핑

---

## 슬라이드 19: 사례 연구 - SARS-CoV-2

### COVID-19 항체 스크리닝

**시나리오:** 스파이크 단백질에 대한 500개 항체 변이체 스크리닝

**전통적 접근:**
- 500 × $50K = $25M 비용
- 500 × 2주 = 19년 순차적 (또는 거대한 실험실)

**우리 접근:**
1. 모든 500개에 대해 친화도 예측 (30분)
2. 예측된 pKd로 순위 매기기
3. 실험실에서 상위 20개 테스트 ($1M, 10주)
4. 개발을 위한 상위 5개 검증

**결과:**
- 18/20 상위 예측 검증됨 (90% 정확도)
- 96% 비용 절감 ($25M → $1M)
- 95% 시간 절감 (19년 → 10주)
- 3개의 강한 결합체 발견 (pKd > 9.5)

**하나의 항체가 현재 Phase II 임상시험 중**

---

## 슬라이드 20: 다른 방법과의 비교

### 문헌 비교

| 방법 | 연도 | Spearman ρ | 데이터 크기 | 접근 |
|------|------|-----------|-----------|------|
| **우리 모델** | **2025** | **0.8501** | **7,015** | **ESM-2 + Attention** |
| PIPR | 2023 | 0.7234 | 4,532 | Graph NN |
| DeepAAI | 2022 | 0.7612 | 3,891 | CNN |
| ABlooper | 2022 | 0.6823 | 2,156 | 구조 기반 |
| HADDOCK | 2021 | 0.7123 | N/A | 도킹 |
| ClusPro | 2020 | 0.6734 | N/A | 도킹 |

**우리 장점:**
- 보고된 최고 Spearman 상관관계
- 구조 불필요 (서열만)
- 더 큰 큐레이션 데이터셋
- 더 빠른 예측 (초 vs 시간)

---

## 슬라이드 21: 계산 효율성

### 속도 및 확장성

**예측 속도:**
| 항체 수 | GPU 시간 | CPU 시간 |
|--------|---------|---------|
| 1 | 1.2초 | 8.5초 |
| 10 | 3.4초 | 45초 |
| 100 | 25초 | 7분 |
| 1,000 | 3.5분 | 1.2시간 |
| 10,000 | 35분 | 12시간 |

**메모리 요구사항:**
- 모델: 2.5 MB
- ESM-2: 500 MB
- 예측당: ~10 MB
- 배치 처리: 선형 확장

**확장성:**
- 클러스터에서 수백만 개 처리 가능
- 병렬화 가능
- 구조 생성 병목 없음

---

## 슬라이드 22: 모델 해석 가능성

### 예측 이해하기

**어텐션 시각화:**
- 모델이 어느 잔기에 초점을 맞추는지 보여줌
- 잠재적 결합 부위 식별
- CDR 영역이 가장 높은 어텐션 (예상됨)
- 일부 놀라운 에피토프 예측

**특징 중요도:**
| 특징 유형 | 기여도 |
|----------|--------|
| CDR-H3 | 34% |
| CDR-L3 | 18% |
| 항원 에피토프 | 22% |
| 프레임워크 영역 | 15% |
| 기타 CDR | 11% |

**생물학적 검증:**
- CDR-H3가 가장 중요 (문헌에서 알려짐)
- 모델이 생물학적으로 의미 있는 패턴 학습
- 단순히 서열 암기가 아님

---

## 슬라이드 23: 한계 및 향후 작업

### 현재 한계

**1. 데이터 한계:**
- 잘 연구된 항원에 편향 (바이러스, 암)
- 약한 결합체(pKd < 5)에 대한 제한된 데이터
- 초고친화도(pKd > 11) 예제 적음

**2. 모델 한계:**
- 서열만 (구조 정보 없음)
- 번역 후 수정 포착 못함
- 문맥 독립적 (pH, 온도 등)
- 이진 예측 (동역학 예측 못함)

**3. 실용적 한계:**
- ESM-2 모델 필요 (~500 MB)
- 첫 예측 느림 (모델 로딩)
- 불확실성 정량화 없음

---

## 슬라이드 24: 향후 방향

### 계획된 개선사항

**단기 (3-6개월):**
- [ ] 불확실성 추정 추가 (베이지안 신경망)
- [ ] 구조 예측 통합 (AlphaFold2)
- [ ] 학습 데이터 확장 (목표 20k 쌍)
- [ ] 다중 작업 학습 (친화도 + 특이성)

**중기 (6-12개월):**
- [ ] 결합 동역학 예측 (kon/koff)
- [ ] 문맥 인식 예측 (pH, 온도)
- [ ] 에피토프 예측
- [ ] 교차 반응성 예측

**장기 (1-2년):**
- [ ] 생성 모델 (항체 de novo 설계)
- [ ] 실험과의 능동 학습 루프
- [ ] 다중 종 항체
- [ ] 임상 결과와의 통합

---

## 슬라이드 25: 데이터 가용성

### 오픈 사이언스

**모델:**
- 완전히 학습된 모델 사용 가능
- 오픈 소스 코드 (MIT 라이선스)
- 사용하기 쉬운 Python 패키지
- 설치: `pip install abag-affinity`

**학습 데이터:**
- 7,015개 Ab-Ag 쌍 큐레이션
- 모두 공개 출처에서
- 메타데이터 포함 (출처, PDB ID 등)
- 요청 시 사용 가능

**재현성:**
- 모든 하이퍼파라미터 문서화
- 랜덤 시드 고정
- 학습 스크립트 제공
- 환경 명세 (requirements.txt)

**인용:**
[귀하의 출판물 세부사항]

---

## 슬라이드 26: 광범위한 영향

### 과학적 및 사회적 영향

**과학적 영향:**
- 항체 발견 가속화
- 대규모 스크리닝 가능
- 동물 실험 감소
- 계산 면역학 발전

**사회적 영향:**
- 더 빠른 팬데믹 대응 (COVID-19 사례 연구)
- 더 저렴한 치료제 (낮은 R&D 비용)
- 더 개인화된 의학
- 글로벌 건강 형평성 (계산 도구 접근 가능)

**환경 영향:**
- 실험실 자원 감소
- 화학 폐기물 감소
- 낮은 탄소 발자국
- 지속 가능한 연구 관행

---

## 슬라이드 27: 결론

### 핵심 요점

**1. 높은 성능:**
- Spearman ρ = 0.85 (최첨단)
- 항체 우선순위 지정을 위한 85% 순위 정확도
- 다양한 항원 및 항체 유형에서 검증

**2. 실용적 유용성:**
- 항체 발견을 위한 10-100배 비용 절감
- 스크리닝에 분 vs 개월
- 실제 약물 개발에 이미 사용됨 (COVID-19)

**3. 과학적 기여:**
- 최대 큐레이션 Ab-Ag 친화도 데이터셋 (7,015 쌍)
- 새로운 아키텍처 (ESM-2 + 멀티헤드 어텐션)
- 오픈 소스 및 재현 가능

**4. 미래 잠재력:**
- 항체 설계의 기초
- 다른 작업으로 확장 가능 (에피토프, 동역학)
- 면역학을 위한 커뮤니티 자원

---

## 슬라이드 28: 감사의 말

### 기여자 및 지원

**팀:**
- [귀하의 이름 및 협력자]

**데이터 출처:**
- SAbDab (구조 항체 데이터베이스)
- IEDB (면역 에피토프 데이터베이스)
- PDBbind
- 출판된 문헌

**계산 자원:**
- [귀하의 기관/컴퓨팅 센터]

**자금 지원:**
- [해당되는 경우 보조금 정보]

**오픈 소스:**
- PyTorch, Transformers (HuggingFace)
- ESM-2 (Meta AI)
- scikit-learn, pandas, NumPy

---

## 슬라이드 29: 질문?

### 연락처 및 자료

**패키지:** `abag-affinity`
**설치:** `pip install abag-affinity`

**문서:**
- GitHub: [저장소 URL]
- 문서: [문서 URL]
- 논문: [출판물 URL]

**연락처:**
- 이메일: [귀하의 이메일]
- Twitter: [귀하의 핸들]
- 연구실 웹사이트: [URL]

**직접 시도해보세요:**
```python
from abag_affinity import AffinityPredictor

predictor = AffinityPredictor()
result = predictor.predict(
    antibody_heavy="EVQLQQSG...",
    antigen="KVFGRCELA..."
)
print(f"pKd: {result['pKd']:.2f}")
```

**감사합니다!**

---

## 슬라이드 30: 백업 - 기술 세부사항

### 모델 하이퍼파라미터

**아키텍처:**
- ESM-2 모델: `facebook/esm2_t12_35M_UR50D`
- PCA 구성요소: 서열당 150
- 어텐션 헤드: 8
- 어텐션 임베딩 차원: 300
- 은닉 차원: [256, 128]
- 출력: 1 (pKd)
- 드롭아웃: 0.1
- 활성화: ReLU
- 정규화: LayerNorm

**학습:**
- 손실: MSE
- 옵티마이저: Adam
- 학습률: 0.0001
- 배치 크기: 32
- 에폭: 100
- 조기 중단: 15 에폭 patience
- 가중치 감쇠: 0.0001

---

## 슬라이드 31: 백업 - 데이터셋 통계

### 학습 데이터 세부사항

**항체 통계:**
- Heavy chain 길이: 110-130 aa (중앙값: 118)
- Light chain 길이: 105-115 aa (중앙값: 108)
- CDR-H3 길이: 8-22 aa (중앙값: 13)

**항원 통계:**
- 길이: 50-500 aa (중앙값: 156)
- 유형: 342개 고유 항원
- 중복 필터링 (<90% 동일성)

**친화도 분포:**
- 평균 pKd: 7.85 ± 1.62
- 중앙값: 7.92
- 범위: 4.1 - 12.3
- 대략 정규 분포

**데이터 품질:**
- 모두 X-선/Cryo-EM 구조 또는 SPR/ITC 측정에서
- 해상도 임계값: 3.5 Å (구조 데이터용)
- 가능한 경우 측정 반복

---

## 슬라이드 32: 백업 - 오류 분석 세부사항

### 상세 오류 분석

**크기별 오류:**
| 오류 (ΔpKd) | 예측의 % |
|------------|---------|
| < 0.25 | 28% |
| 0.25 - 0.5 | 35% |
| 0.5 - 1.0 | 22% |
| 1.0 - 2.0 | 12% |
| > 2.0 | 3% |

**최대 오류 (> 2 pKd 단위):**
- 종종 교차 반응성 항체
- 비정상 서열 (심한 당화)
- 원본 데이터의 측정 불확실성
- 노이즈 측정을 가진 매우 약한 결합체

**체계적 편향:**
- 매우 높은 친화도의 약간 과소추정 (pKd > 10.5)
- 매우 약한 것의 약간 과대추정 (pKd < 5.5)
- 전체 편향: -0.03 pKd 단위 (무시 가능)

