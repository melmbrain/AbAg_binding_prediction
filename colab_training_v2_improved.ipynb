{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# AbAg Binding Affinity Prediction - IMPROVED Training v2\n",
    "\n",
    "**Improvements over v1:**\n",
    "- ‚úÖ GELU activation (instead of ReLU) - smoother gradients\n",
    "- ‚úÖ Deeper architecture: 150 ‚Üí 512 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 1 (vs 150 ‚Üí 256 ‚Üí 128 ‚Üí 1)\n",
    "- ‚úÖ 10x stronger weights for very strong/weak binders\n",
    "- ‚úÖ Lower learning rate: 0.0001 (vs 0.001) - more stable training\n",
    "- ‚úÖ Focal loss option - focuses on hard examples\n",
    "- ‚úÖ Gradient clipping - prevents exploding gradients\n",
    "- ‚úÖ Better initialization - Xavier/He initialization\n",
    "\n",
    "**Expected Results:**\n",
    "- Overall RMSE: 1.48 ‚Üí 0.8-1.0\n",
    "- Very strong RMSE: 2.94 ‚Üí 1.0-1.5 (67% improvement)\n",
    "- Spearman œÅ: 0.39 ‚Üí 0.65-0.75\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset:** 390,757 samples (330,762 with features)\n",
    "**Training time:** ~10-12 hours on T4 GPU (100 epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup - GPU and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Enable GPU in Runtime settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers scikit-learn pandas numpy tqdm matplotlib seaborn\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths - MODIFY THIS to match your Google Drive location\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/AbAg_data/merged_with_all_features.csv\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/AbAg_data/models_v2\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Copy data to local for faster training\n",
    "LOCAL_DATA_PATH = \"/content/merged_with_all_features.csv\"\n",
    "\n",
    "print(f\"Data path: {DRIVE_DATA_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "if os.path.exists(DRIVE_DATA_PATH):\n",
    "    print(f\"‚úÖ Data file found! Size: {os.path.getsize(DRIVE_DATA_PATH) / 1e6:.1f} MB\")\n",
    "    \n",
    "    print(\"Copying data to local storage for faster I/O...\")\n",
    "    !cp \"{DRIVE_DATA_PATH}\" \"{LOCAL_DATA_PATH}\"\n",
    "    print(\"‚úÖ Data copied to local storage!\")\n",
    "    \n",
    "    DATA_PATH = LOCAL_DATA_PATH\n",
    "else:\n",
    "    print(f\"‚ùå Data file not found at: {DRIVE_DATA_PATH}\")\n",
    "    print(\"\\nPlease upload 'merged_with_all_features.csv' to your Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Constants\n",
    "BINS = [0, 5, 7, 9, 11, 16]\n",
    "BIN_LABELS = ['very_weak', 'weak', 'moderate', 'strong', 'very_strong']\n",
    "\n",
    "print(\"‚úÖ Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffinityDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "print(\"‚úÖ Dataset class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. IMPROVED Model Architecture (GELU + Deeper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedAffinityPredictor(nn.Module):\n",
    "    \"\"\"Improved model with GELU activation and deeper architecture\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=150, hidden_dims=[512, 256, 128, 64], dropout=0.3):\n",
    "        super(ImprovedAffinityPredictor, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            # Linear layer\n",
    "            linear = nn.Linear(prev_dim, hidden_dim)\n",
    "            \n",
    "            # Xavier/He initialization for better gradient flow\n",
    "            nn.init.xavier_uniform_(linear.weight)\n",
    "            nn.init.zeros_(linear.bias)\n",
    "            \n",
    "            layers.extend([\n",
    "                linear,\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.GELU(),  # GELU instead of ReLU - smoother gradients\n",
    "                nn.Dropout(dropout if i < len(hidden_dims) - 1 else dropout * 0.5)  # Less dropout in final layers\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        output_layer = nn.Linear(prev_dim, 1)\n",
    "        nn.init.xavier_uniform_(output_layer.weight)\n",
    "        nn.init.zeros_(output_layer.bias)\n",
    "        layers.append(output_layer)\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()\n",
    "\n",
    "print(\"‚úÖ Improved model class defined!\")\n",
    "print(\"   - GELU activation (smoother than ReLU)\")\n",
    "print(\"   - Deeper: 512 ‚Üí 256 ‚Üí 128 ‚Üí 64\")\n",
    "print(\"   - Xavier initialization\")\n",
    "print(\"   - Adaptive dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Functions (Weighted MSE + Focal Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELoss(nn.Module):\n",
    "    \"\"\"MSE with class-based weighting\"\"\"\n",
    "    \n",
    "    def __init__(self, bin_weights, bins_edges):\n",
    "        super().__init__()\n",
    "        self.bin_weights = bin_weights\n",
    "        self.bins = bins_edges\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        weights = torch.ones_like(targets)\n",
    "        for i, (low, high) in enumerate(zip(self.bins[:-1], self.bins[1:])):\n",
    "            mask = (targets >= low) & (targets < high)\n",
    "            weights[mask] = self.bin_weights[i]\n",
    "        \n",
    "        mse = (predictions - targets) ** 2\n",
    "        weighted_mse = mse * weights\n",
    "        return weighted_mse.mean()\n",
    "\n",
    "\n",
    "class FocalMSELoss(nn.Module):\n",
    "    \"\"\"Focal loss for regression - focuses on hard examples\"\"\"\n",
    "    \n",
    "    def __init__(self, bin_weights, bins_edges, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.bin_weights = bin_weights\n",
    "        self.bins = bins_edges\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Class weights\n",
    "        weights = torch.ones_like(targets)\n",
    "        for i, (low, high) in enumerate(zip(self.bins[:-1], self.bins[1:])):\n",
    "            mask = (targets >= low) & (targets < high)\n",
    "            weights[mask] = self.bin_weights[i]\n",
    "        \n",
    "        # Focal weighting - down-weight easy examples\n",
    "        mse = (predictions - targets) ** 2\n",
    "        focal_weight = mse ** (self.gamma / 2)  # Higher error = higher weight\n",
    "        \n",
    "        weighted_mse = mse * weights * (1 + focal_weight)\n",
    "        return weighted_mse.mean()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Loss functions defined!\")\n",
    "print(\"   - WeightedMSELoss: Class-based weighting\")\n",
    "print(\"   - FocalMSELoss: Focuses on hard examples (gamma=2.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(f\"‚úÖ Loaded {len(df):,} samples\")\n",
    "\n",
    "# Filter samples with features\n",
    "pca_cols = [f'esm2_pca_{i}' for i in range(150)]\n",
    "df_with_features = df[df[pca_cols[0]].notna()].copy()\n",
    "print(f\"‚úÖ Samples with features: {len(df_with_features):,}\")\n",
    "\n",
    "# Create affinity bins\n",
    "df_with_features['affinity_bin'] = pd.cut(\n",
    "    df_with_features['pKd'], bins=BINS, labels=BIN_LABELS, include_lowest=True\n",
    ")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\nAffinity Distribution:\")\n",
    "for label in BIN_LABELS:\n",
    "    count = (df_with_features['affinity_bin'] == label).sum()\n",
    "    pct = count / len(df_with_features) * 100\n",
    "    print(f\"  {label:<15}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal: {len(df_with_features):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X = df_with_features[pca_cols].values\n",
    "y = df_with_features['pKd'].values\n",
    "\n",
    "# Train/val/test split (same as v1 for comparison)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.15/0.85, random_state=42)\n",
    "\n",
    "print(f\"Train set: {len(X_train):,}\")\n",
    "print(f\"Val set: {len(X_val):,}\")\n",
    "print(f\"Test set: {len(X_test):,}\")\n",
    "\n",
    "# Calculate IMPROVED class weights (10x stronger for extremes)\n",
    "y_train_binned = pd.cut(y_train, bins=BINS, labels=BIN_LABELS, include_lowest=True)\n",
    "bin_counts = y_train_binned.value_counts().sort_index()\n",
    "total_samples = len(y_train)\n",
    "bin_weights = {}\n",
    "\n",
    "for label in BIN_LABELS:\n",
    "    count = bin_counts.get(label, 1)\n",
    "    base_weight = total_samples / (len(BIN_LABELS) * count)\n",
    "    \n",
    "    # 10x stronger weight for very strong and very weak\n",
    "    if label in ['very_strong', 'very_weak']:\n",
    "        bin_weights[label] = base_weight * 10\n",
    "    else:\n",
    "        bin_weights[label] = base_weight\n",
    "\n",
    "print(\"\\nIMPROVED Class Weights (10x stronger for extremes):\")\n",
    "for label, weight in bin_weights.items():\n",
    "    marker = \"‚≠ê\" if label in ['very_strong', 'very_weak'] else \"  \"\n",
    "    print(f\"  {marker} {label:<15}: {weight:.2f}\")\n",
    "\n",
    "# Convert to tensor\n",
    "bin_weights_tensor = torch.FloatTensor([bin_weights[l] for l in BIN_LABELS]).cuda()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AffinityDataset(X_train, y_train)\n",
    "val_dataset = AffinityDataset(X_val, y_val)\n",
    "test_dataset = AffinityDataset(X_test, y_test)\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0001  # 10x lower than v1 for stability\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "USE_FOCAL_LOSS = True  # Set to False to use weighted MSE instead\n",
    "GRADIENT_CLIP = 1.0  # Clip gradients to prevent explosion\n",
    "\n",
    "print(f\"IMPROVED Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE} (10x lower than v1)\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Loss: {'Focal MSE' if USE_FOCAL_LOSS else 'Weighted MSE'}\")\n",
    "print(f\"  Gradient clipping: {GRADIENT_CLIP}\")\n",
    "print(f\"\\n  Model: 150 ‚Üí 512 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 1\")\n",
    "print(f\"  Activation: GELU (vs ReLU in v1)\")\n",
    "print(f\"  Class weights: 10x stronger for extremes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"‚úÖ Data loaders created!\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IMPROVED model\n",
    "model = ImprovedAffinityPredictor(\n",
    "    input_dim=150,\n",
    "    hidden_dims=[512, 256, 128, 64],  # Deeper than v1\n",
    "    dropout=0.3\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Loss and optimizer\n",
    "if USE_FOCAL_LOSS:\n",
    "    criterion = FocalMSELoss(bin_weights_tensor, BINS, gamma=2.0)\n",
    "    print(\"Using Focal MSE Loss (focuses on hard examples)\")\n",
    "else:\n",
    "    criterion = WeightedMSELoss(bin_weights_tensor, BINS)\n",
    "    print(\"Using Weighted MSE Loss\")\n",
    "\n",
    "optimizer = optim.AdamW(  # AdamW instead of Adam - better regularization\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-4,  # Stronger regularization\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Cosine annealing scheduler - gradually reduces learning rate\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=20,  # Restart every 20 epochs\n",
    "    T_mult=2,\n",
    "    eta_min=LEARNING_RATE * 0.01\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model initialized!\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Optimizer: AdamW (better than Adam)\")\n",
    "print(f\"  Scheduler: Cosine Annealing with Warm Restarts\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training Loop (with Gradient Clipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with improvements\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rates = []\n",
    "train_start = time.time()\n",
    "\n",
    "print(\"Starting IMPROVED training...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
    "    \n",
    "    for features, labels in train_pbar:\n",
    "        features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping - prevents exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_pbar:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            predictions = model(features)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Update learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    learning_rates.append(current_lr)\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, LR: {current_lr:.6f}, Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'config': {\n",
    "                'hidden_dims': [512, 256, 128, 64],\n",
    "                'dropout': 0.3,\n",
    "                'activation': 'GELU',\n",
    "                'learning_rate': LEARNING_RATE,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'focal_loss': USE_FOCAL_LOSS\n",
    "            }\n",
    "        }, f'{OUTPUT_DIR}/best_model_v2.pth')\n",
    "        print(f\"  ‚úÖ New best model saved! (val_loss: {val_loss:.4f})\")\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{OUTPUT_DIR}/checkpoint_v2_epoch_{epoch+1}.pth')\n",
    "        print(f\"  üíæ Checkpoint saved!\")\n",
    "\n",
    "total_time = time.time() - train_start\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ Training complete! Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves with learning rate\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate schedule\n",
    "axes[1].plot(learning_rates, linewidth=2, color='green')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1].set_title('Learning Rate Schedule (Cosine Annealing)', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/training_curves_v2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Training curves saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f'{OUTPUT_DIR}/best_model_v2.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Best model loaded from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Val loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "print(\"Running evaluation on test set...\")\n",
    "with torch.no_grad():\n",
    "    for features, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        features = features.to(DEVICE)\n",
    "        predictions = model(features)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_targets.extend(labels.numpy())\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_targets = np.array(test_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(test_targets, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_targets, test_predictions)\n",
    "spearman = spearmanr(test_targets, test_predictions)[0]\n",
    "pearson = pearsonr(test_targets, test_predictions)[0]\n",
    "r2 = 1 - (np.sum((test_targets - test_predictions)**2) / np.sum((test_targets - test_targets.mean())**2))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST SET PERFORMANCE (v2 IMPROVED)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"RMSE:        {rmse:.4f}\")\n",
    "print(f\"MAE:         {mae:.4f}\")\n",
    "print(f\"Spearman œÅ:  {spearman:.4f}\")\n",
    "print(f\"Pearson r:   {pearson:.4f}\")\n",
    "print(f\"R¬≤:          {r2:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-bin metrics\n",
    "test_df = pd.DataFrame({\n",
    "    'target': test_targets,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "test_df['affinity_bin'] = pd.cut(test_df['target'], bins=BINS, labels=BIN_LABELS, include_lowest=True)\n",
    "\n",
    "print(\"\\nPER-BIN PERFORMANCE:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Bin':<15} | {'Count':<8} | {'RMSE':<8} | {'MAE':<8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for label in BIN_LABELS:\n",
    "    bin_data = test_df[test_df['affinity_bin'] == label]\n",
    "    if len(bin_data) > 0:\n",
    "        bin_rmse = np.sqrt(mean_squared_error(bin_data['target'], bin_data['prediction']))\n",
    "        bin_mae = mean_absolute_error(bin_data['target'], bin_data['prediction'])\n",
    "        marker = \"‚≠ê\" if label in ['very_strong', 'very_weak'] else \"  \"\n",
    "        print(f\"{marker} {label:<13} | {len(bin_data):<8} | {bin_rmse:<8.4f} | {bin_mae:<8.4f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Comparison with v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show comparison with v1 results\n",
    "v1_results = {\n",
    "    'RMSE': 1.4761,\n",
    "    'MAE': 1.3011,\n",
    "    'Spearman': 0.3912,\n",
    "    'Pearson': 0.7265,\n",
    "    'R2': 0.5188,\n",
    "    'very_strong_rmse': 2.9394\n",
    "}\n",
    "\n",
    "v2_very_strong_rmse = np.sqrt(mean_squared_error(\n",
    "    test_df[test_df['affinity_bin'] == 'very_strong']['target'],\n",
    "    test_df[test_df['affinity_bin'] == 'very_strong']['prediction']\n",
    "))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: v1 vs v2 (IMPROVED)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<20} | {'v1':<12} | {'v2 (improved)':<12} | {'Change':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "metrics = [\n",
    "    ('RMSE', v1_results['RMSE'], rmse, 'lower is better'),\n",
    "    ('MAE', v1_results['MAE'], mae, 'lower is better'),\n",
    "    ('Spearman œÅ', v1_results['Spearman'], spearman, 'higher is better'),\n",
    "    ('Pearson r', v1_results['Pearson'], pearson, 'higher is better'),\n",
    "    ('R¬≤', v1_results['R2'], r2, 'higher is better'),\n",
    "    ('Very Strong RMSE', v1_results['very_strong_rmse'], v2_very_strong_rmse, 'lower is better')\n",
    "]\n",
    "\n",
    "for metric_name, v1_val, v2_val, direction in metrics:\n",
    "    if 'lower' in direction:\n",
    "        change_pct = ((v1_val - v2_val) / v1_val) * 100\n",
    "        symbol = \"‚úÖ\" if v2_val < v1_val else \"‚ùå\"\n",
    "    else:\n",
    "        change_pct = ((v2_val - v1_val) / v1_val) * 100\n",
    "        symbol = \"‚úÖ\" if v2_val > v1_val else \"‚ùå\"\n",
    "    \n",
    "    print(f\"{symbol} {metric_name:<18} | {v1_val:<12.4f} | {v2_val:<12.4f} | {change_pct:+.1f}%\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions vs targets\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(test_targets, test_predictions, alpha=0.3, s=10)\n",
    "plt.plot([test_targets.min(), test_targets.max()], [test_targets.min(), test_targets.max()], 'r--', lw=2)\n",
    "plt.xlabel('True pKd', fontsize=12)\n",
    "plt.ylabel('Predicted pKd', fontsize=12)\n",
    "plt.title(f'v2 IMPROVED - Test Set Predictions\\nSpearman œÅ = {spearman:.4f}, RMSE = {rmse:.4f}', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.savefig(f'{OUTPUT_DIR}/predictions_vs_targets_v2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Prediction plot saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals analysis\n",
    "residuals = test_predictions - test_targets\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].scatter(test_predictions, residuals, alpha=0.3, s=10)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0].set_xlabel('Predicted pKd', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals (Predicted - True)', fontsize=12)\n",
    "axes[0].set_title('Residuals vs Predictions', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Residuals', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title(f'Residuals Distribution\\nMean = {residuals.mean():.4f}, Std = {residuals.std():.4f}', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/residuals_analysis_v2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Residuals plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_summary = f\"\"\"\n",
    "AbAg Binding Affinity Prediction - v2 IMPROVED Results\n",
    "{'='*70}\n",
    "\n",
    "Model Improvements:\n",
    "  - GELU activation (vs ReLU in v1)\n",
    "  - Deeper architecture: 512 ‚Üí 256 ‚Üí 128 ‚Üí 64 (vs 256 ‚Üí 128 in v1)\n",
    "  - 10x stronger weights for very strong/weak binders\n",
    "  - Lower learning rate: 0.0001 (vs 0.001 in v1)\n",
    "  - {'Focal MSE Loss' if USE_FOCAL_LOSS else 'Weighted MSE Loss'}\n",
    "  - Gradient clipping: {GRADIENT_CLIP}\n",
    "  - AdamW optimizer with cosine annealing\n",
    "\n",
    "Training:\n",
    "  - Epochs: {EPOCHS}\n",
    "  - Batch size: {BATCH_SIZE}\n",
    "  - Training samples: {len(X_train):,}\n",
    "  - Validation samples: {len(X_val):,}\n",
    "  - Test samples: {len(X_test):,}\n",
    "  - Total training time: {total_time/3600:.2f} hours\n",
    "\n",
    "Test Set Performance:\n",
    "  - RMSE:       {rmse:.4f} (v1: {v1_results['RMSE']:.4f})\n",
    "  - MAE:        {mae:.4f} (v1: {v1_results['MAE']:.4f})\n",
    "  - Spearman œÅ: {spearman:.4f} (v1: {v1_results['Spearman']:.4f})\n",
    "  - Pearson r:  {pearson:.4f} (v1: {v1_results['Pearson']:.4f})\n",
    "  - R¬≤:         {r2:.4f} (v1: {v1_results['R2']:.4f})\n",
    "\n",
    "Per-Bin Performance:\n",
    "\"\"\"\n",
    "\n",
    "for label in BIN_LABELS:\n",
    "    bin_data = test_df[test_df['affinity_bin'] == label]\n",
    "    if len(bin_data) > 0:\n",
    "        bin_rmse = np.sqrt(mean_squared_error(bin_data['target'], bin_data['prediction']))\n",
    "        bin_mae = mean_absolute_error(bin_data['target'], bin_data['prediction'])\n",
    "        marker = \"‚≠ê\" if label in ['very_strong', 'very_weak'] else \"  \"\n",
    "        results_summary += f\"{marker} - {label:<15}: RMSE={bin_rmse:6.4f}, MAE={bin_mae:6.4f}, N={len(bin_data):6,}\\n\"\n",
    "\n",
    "results_summary += f\"\\n{'='*70}\\n\"\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/evaluation_results_v2.txt', 'w') as f:\n",
    "    f.write(results_summary)\n",
    "\n",
    "print(results_summary)\n",
    "print(f\"‚úÖ Results saved to {OUTPUT_DIR}/evaluation_results_v2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'true_pKd': test_targets,\n",
    "    'predicted_pKd': test_predictions,\n",
    "    'residual': residuals,\n",
    "    'affinity_bin': test_df['affinity_bin']\n",
    "})\n",
    "\n",
    "results_df.to_csv(f'{OUTPUT_DIR}/test_predictions_v2.csv', index=False)\n",
    "print(f\"‚úÖ Predictions saved to {OUTPUT_DIR}/test_predictions_v2.csv\")\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'metrics': {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'spearman': spearman,\n",
    "        'pearson': pearson,\n",
    "        'r2': r2\n",
    "    },\n",
    "    'config': {\n",
    "        'input_dim': 150,\n",
    "        'hidden_dims': [512, 256, 128, 64],\n",
    "        'dropout': 0.3,\n",
    "        'activation': 'GELU',\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'focal_loss': USE_FOCAL_LOSS\n",
    "    }\n",
    "}, f'{OUTPUT_DIR}/final_model_v2.pth')\n",
    "\n",
    "print(f\"\\n‚úÖ All files saved to Google Drive: {OUTPUT_DIR}\")\n",
    "print(f\"\\nYou can now download the trained model from Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
