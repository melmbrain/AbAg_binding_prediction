{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Antibody-Antigen Binding Prediction Training\n",
    "\n",
    "## Complete Step-by-Step Guide with Explanations\n",
    "\n",
    "This notebook trains a deep learning model to predict antibody-antigen binding affinity (pKd values).\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to set up a production-ready training pipeline\n",
    "- Modern best practices (warmup, early stopping, comprehensive metrics)\n",
    "- How to properly evaluate deep learning models\n",
    "\n",
    "**Architecture:**\n",
    "- IgT5 encoder (antibody sequences)\n",
    "- ESM-2 encoder (antigen sequences)  \n",
    "- Trainable regression head\n",
    "\n",
    "**Total runtime:** ~2-3 hours on Tesla T4\n",
    "\n",
    "**Data location:** Google Drive folder `AbAg_Training_02`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Environment Setup\n",
    "\n",
    "**What this does:**\n",
    "- Checks if GPU is available\n",
    "- Installs required packages\n",
    "- Enables optimization flags (TF32, cuDNN auto-tuner)\n",
    "\n",
    "**Why it matters:**\n",
    "- GPU is essential for training (50x faster than CPU)\n",
    "- Optimization flags give 20-30% speedup\n",
    "- Ensures all dependencies are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not available! Training will be very slow.\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages (Colab-compatible versions)\nprint(\"Installing required packages...\\n\")\n\n# Install packages compatible with current Colab environment\n!pip install -q transformers>=4.41.0\n!pip install -q sentencepiece\n\nprint(\"\\n‚úÖ All packages installed successfully!\")\nprint(\"‚úÖ Using Colab's pre-installed numpy, pandas, scikit-learn, scipy\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable optimization flags\n",
    "import torch\n",
    "\n",
    "# Enable TF32 for faster matrix multiplication on Ampere GPUs\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Enable cuDNN auto-tuner for optimal convolution algorithms\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Disable deterministic mode for speed (reproducibility not critical here)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "print(\"‚úÖ Optimizations enabled:\")\n",
    "print(\"  ‚Ä¢ TF32 matrix multiplication\")\n",
    "print(\"  ‚Ä¢ cuDNN auto-tuner\")\n",
    "print(\"  ‚Ä¢ Non-deterministic mode (faster)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Import Libraries & Define Utilities\n",
    "\n",
    "**What this does:**\n",
    "- Imports all necessary libraries\n",
    "- Defines helper functions for metrics, early stopping, schedulers\n",
    "\n",
    "**Why it matters:**\n",
    "- Metrics: We need to measure performance accurately (12 different metrics)\n",
    "- Early stopping: Prevents overfitting by stopping when performance plateaus\n",
    "- LR scheduler: Warmup + cosine decay improves training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformers (for pre-trained protein language models)\n",
    "from transformers import (\n",
    "    T5Tokenizer, T5EncoderModel,  # IgT5 for antibodies\n",
    "    AutoTokenizer, AutoModel        # ESM-2 for antigens\n",
    ")\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive metrics function\n",
    "def compute_comprehensive_metrics(targets, predictions):\n",
    "    \"\"\"\n",
    "    Compute all 12 standard metrics for regression + classification.\n",
    "    \n",
    "    Args:\n",
    "        targets: True pKd values (numpy array)\n",
    "        predictions: Predicted pKd values (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 12 metrics\n",
    "    \"\"\"\n",
    "    # Regression metrics\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(targets, predictions)\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    \n",
    "    # Correlation metrics (with p-values for statistical significance)\n",
    "    spearman, spearman_p = stats.spearmanr(targets, predictions)\n",
    "    pearson, pearson_p = stats.pearsonr(targets, predictions)\n",
    "    \n",
    "    # Classification metrics for strong binders (pKd >= 9)\n",
    "    strong_binders = targets >= 9.0\n",
    "    predicted_strong = predictions >= 9.0\n",
    "    \n",
    "    # True positives, false positives, etc.\n",
    "    tp = np.sum(strong_binders & predicted_strong)\n",
    "    fp = np.sum(~strong_binders & predicted_strong)\n",
    "    tn = np.sum(~strong_binders & ~predicted_strong)\n",
    "    fn = np.sum(strong_binders & ~predicted_strong)\n",
    "    \n",
    "    # Calculate metrics (handle division by zero)\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        # Regression metrics\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        # Correlation metrics\n",
    "        'spearman': spearman,\n",
    "        'spearman_p': spearman_p,\n",
    "        'pearson': pearson,\n",
    "        'pearson_p': pearson_p,\n",
    "        # Classification metrics\n",
    "        'recall_pkd9': recall * 100,\n",
    "        'precision_pkd9': precision * 100,\n",
    "        'f1_pkd9': f1 * 100,\n",
    "        'specificity_pkd9': specificity * 100,\n",
    "        # Sample counts\n",
    "        'n_samples': len(targets),\n",
    "        'n_strong_binders': int(strong_binders.sum())\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Monitors validation metric and stops training when no improvement.\n",
    "    \n",
    "    Args:\n",
    "        patience: How many epochs to wait for improvement\n",
    "        min_delta: Minimum change to qualify as improvement\n",
    "        mode: 'max' for metrics like Spearman, 'min' for loss\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0001, mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def __call__(self, score, epoch):\n",
    "        \"\"\"\n",
    "        Check if training should stop.\n",
    "        \n",
    "        Args:\n",
    "            score: Current validation metric\n",
    "            epoch: Current epoch number\n",
    "        \n",
    "        Returns:\n",
    "            True if should stop, False otherwise\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        # Check for improvement\n",
    "        if self.mode == 'max':\n",
    "            improved = score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            improved = score < (self.best_score - self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"   No improvement for {self.counter}/{self.patience} epochs\")\n",
    "            \n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è Early stopping triggered!\")\n",
    "                    print(f\"   No improvement for {self.patience} epochs\")\n",
    "                    print(f\"   Best score: {self.best_score:.4f} at epoch {self.best_epoch+1}\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ EarlyStopping class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler with warmup\n",
    "def get_warmup_cosine_scheduler(optimizer, warmup_epochs, total_epochs):\n",
    "    \"\"\"\n",
    "    Create LR scheduler with linear warmup followed by cosine decay.\n",
    "    \n",
    "    Schedule:\n",
    "    - Epochs 0 to warmup_epochs: Linear increase from 0 to max_lr\n",
    "    - Epochs warmup_epochs to total_epochs: Cosine decay to ~0\n",
    "    \n",
    "    Args:\n",
    "        optimizer: PyTorch optimizer\n",
    "        warmup_epochs: Number of epochs for warmup phase\n",
    "        total_epochs: Total number of training epochs\n",
    "    \n",
    "    Returns:\n",
    "        LR scheduler\n",
    "    \"\"\"\n",
    "    def lr_lambda(epoch):\n",
    "        # Warmup phase: linear increase\n",
    "        if epoch < warmup_epochs:\n",
    "            return float(epoch) / float(max(1, warmup_epochs))\n",
    "        \n",
    "        # Cosine decay phase\n",
    "        progress = float(epoch - warmup_epochs) / float(max(1, total_epochs - warmup_epochs))\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "print(\"‚úÖ LR scheduler function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal MSE Loss with label smoothing\n",
    "class FocalMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal MSE loss: Focuses more on hard-to-predict samples.\n",
    "    \n",
    "    Regular MSE: loss = (pred - target)^2\n",
    "    Focal MSE: loss = (1 + (pred - target)^2)^gamma * (pred - target)^2\n",
    "    \n",
    "    This increases weight on large errors, helping model focus on outliers.\n",
    "    \n",
    "    Args:\n",
    "        gamma: Focusing parameter (higher = more focus on hard samples)\n",
    "        label_smoothing: Smooth targets toward mean (reduces overconfidence)\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Apply label smoothing if enabled\n",
    "        if self.label_smoothing > 0:\n",
    "            target_mean = target.mean()\n",
    "            target = (1 - self.label_smoothing) * target + self.label_smoothing * target_mean\n",
    "        \n",
    "        # Compute focal MSE\n",
    "        mse = (pred - target) ** 2\n",
    "        focal_weight = (1 + mse) ** self.gamma\n",
    "        return (focal_weight * mse).mean()\n",
    "\n",
    "print(\"‚úÖ FocalMSELoss class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Mount Google Drive & Load Data\n",
    "\n",
    "**What this does:**\n",
    "- Mounts your Google Drive\n",
    "- Loads CSV from `AbAg_Training_02` folder\n",
    "- Explores data distribution\n",
    "- Splits into train/validation/test (70%/15%/15%)\n",
    "- Creates PyTorch Dataset and DataLoader\n",
    "\n",
    "**Why it matters:**\n",
    "- No need to upload data each time\n",
    "- Results saved directly to Drive\n",
    "- Proper data splitting prevents data leakage\n",
    "- DataLoader handles batching and shuffling automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted!\")\n",
    "\n",
    "# Set up paths\n",
    "DRIVE_DIR = '/content/drive/MyDrive/AbAg_Training_02'\n",
    "OUTPUT_DIR = f'{DRIVE_DIR}/training_output'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÇ Working directories:\")\n",
    "print(f\"   Data directory: {DRIVE_DIR}\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in your Drive directory\n",
    "print(\"\\nüìÅ Files in AbAg_Training_02:\")\n",
    "files_in_dir = os.listdir(DRIVE_DIR)\n",
    "csv_files = [f for f in files_in_dir if f.endswith('.csv')]\n",
    "\n",
    "for f in csv_files:\n",
    "    file_path = os.path.join(DRIVE_DIR, f)\n",
    "    file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "    print(f\"   ‚Ä¢ {f} ({file_size:.2f} MB)\")\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"   ‚ö†Ô∏è No CSV files found!\")\n",
    "    print(\"   Please upload your dataset to the AbAg_Training_02 folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset - MODIFY THIS LINE to specify your CSV filename\n",
    "CSV_FILENAME = 'agab_phase2_full.csv'  # ‚Üê CHANGE THIS to your actual CSV filename\n",
    "\n",
    "csv_path = os.path.join(DRIVE_DIR, CSV_FILENAME)\n",
    "\n",
    "print(f\"Loading dataset from: {csv_path}\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "print(f\"\\n   pKd Statistics:\")\n",
    "print(f\"      Min:  {df['pKd'].min():.2f}\")\n",
    "print(f\"      Max:  {df['pKd'].max():.2f}\")\n",
    "print(f\"      Mean: {df['pKd'].mean():.2f}\")\n",
    "print(f\"      Std:  {df['pKd'].std():.2f}\")\n",
    "\n",
    "# Count strong binders (pKd >= 9)\n",
    "strong_binders = (df['pKd'] >= 9.0).sum()\n",
    "strong_pct = 100 * strong_binders / len(df)\n",
    "print(f\"\\n   Strong Binders (pKd‚â•9): {strong_binders:,} ({strong_pct:.2f}%)\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\n   First 3 samples:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test (70%/15%/15%)\n",
    "print(\"Splitting data...\\n\")\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Split temp into 50/50 -> 15% val, 15% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create quick validation set (5% of val set for speed during training)\n",
    "val_df_quick = val_df.sample(frac=0.05, random_state=42)\n",
    "\n",
    "print(\"üìä Dataset splits:\")\n",
    "print(f\"   Train:     {len(train_df):,} samples ({100*len(train_df)/len(df):.1f}%)\")\n",
    "print(f\"   Val:       {len(val_df):,} samples ({100*len(val_df)/len(df):.1f}%)\")\n",
    "print(f\"   Val Quick: {len(val_df_quick):,} samples ({100*len(val_df_quick)/len(df):.2f}%)\")\n",
    "print(f\"   Test:      {len(test_df):,} samples ({100*len(test_df)/len(df):.1f}%)\")\n",
    "print(\"\\n   Note: During training we use 'Val Quick' for speed.\")\n",
    "print(\"         After training we evaluate on full Val and Test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Dataset class\n",
    "class AbAgDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for antibody-antigen pairs.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - antibody_seqs: List of antibody sequences (strings)\n",
    "        - antigen_seqs: List of antigen sequences (strings)\n",
    "        - pKd: Tensor of binding affinities\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'antibody_seqs': row['antibody_sequence'],\n",
    "            'antigen_seqs': row['antigen_sequence'],\n",
    "            'pKd': torch.tensor(row['pKd'], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Combines individual samples into a batch.\n",
    "    \n",
    "    Since sequences have variable length, we keep them as lists.\n",
    "    Tokenization happens inside the model forward pass.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'antibody_seqs': [item['antibody_seqs'] for item in batch],\n",
    "        'antigen_seqs': [item['antigen_seqs'] for item in batch],\n",
    "        'pKd': torch.stack([item['pKd'] for item in batch])\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Collate function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AbAgDataset(train_df)\n",
    "val_dataset_quick = AbAgDataset(val_df_quick)  # For during training\n",
    "val_dataset_full = AbAgDataset(val_df)          # For final evaluation\n",
    "test_dataset = AbAgDataset(test_df)             # For final evaluation\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # Shuffle for training\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True  # Faster GPU transfer\n",
    ")\n",
    "\n",
    "val_loader_quick = DataLoader(\n",
    "    val_dataset_quick,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # No shuffle for validation\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader_full = DataLoader(\n",
    "    val_dataset_full,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DataLoaders created:\")\n",
    "print(f\"   ‚Ä¢ train_loader: {len(train_loader):,} batches\")\n",
    "print(f\"   ‚Ä¢ val_loader_quick: {len(val_loader_quick):,} batches\")\n",
    "print(f\"   ‚Ä¢ val_loader_full: {len(val_loader_full):,} batches\")\n",
    "print(f\"   ‚Ä¢ test_loader: {len(test_loader):,} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Model Architecture\n",
    "\n",
    "**What this does:**\n",
    "- Loads pre-trained IgT5 (antibody encoder)\n",
    "- Loads pre-trained ESM-2 (antigen encoder)\n",
    "- Freezes encoder weights (saves memory, faster training)\n",
    "- Creates trainable regression head (1792D ‚Üí 1)\n",
    "\n",
    "**Why this architecture:**\n",
    "- Pre-trained encoders already understand protein sequences\n",
    "- We only train the head to predict binding affinity\n",
    "- This requires much less data than training from scratch\n",
    "\n",
    "**Model size:**\n",
    "- Total parameters: ~872M\n",
    "- Trainable: ~2M (only the head)\n",
    "- Frozen: ~870M (the encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class IgT5ESM2Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual-encoder model for antibody-antigen binding prediction.\n",
    "    \n",
    "    Architecture:\n",
    "    1. IgT5 encodes antibody sequence -> 512D embedding\n",
    "    2. ESM-2 encodes antigen sequence -> 1280D embedding\n",
    "    3. Concatenate -> 1792D combined embedding\n",
    "    4. Regression head (MLP) -> single pKd value\n",
    "    \n",
    "    Args:\n",
    "        dropout: Dropout rate for regularization\n",
    "        freeze_encoders: Whether to freeze pre-trained weights\n",
    "        use_checkpointing: Use gradient checkpointing (saves memory)\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout=0.35, freeze_encoders=True, use_checkpointing=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        print(\"üî® Building model...\")\n",
    "        \n",
    "        # Load IgT5 for antibody sequences\n",
    "        print(\"  üì• Loading IgT5 (antibody encoder)...\")\n",
    "        self.igt5_tokenizer = T5Tokenizer.from_pretrained(\"Exscientia/IgT5\")\n",
    "        self.igt5_model = T5EncoderModel.from_pretrained(\"Exscientia/IgT5\")\n",
    "        \n",
    "        # Load ESM-2 for antigen sequences\n",
    "        print(\"  üì• Loading ESM-2 (antigen encoder)...\")\n",
    "        self.esm2_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "        self.esm2_model = AutoModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "        \n",
    "        # Freeze encoders if requested\n",
    "        if freeze_encoders:\n",
    "            print(\"  üîí Freezing encoder weights...\")\n",
    "            for param in self.igt5_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.esm2_model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Enable gradient checkpointing for memory efficiency\n",
    "        if use_checkpointing:\n",
    "            self.igt5_model.gradient_checkpointing_enable()\n",
    "            self.esm2_model.gradient_checkpointing_enable()\n",
    "        \n",
    "        # Get embedding dimensions\n",
    "        self.igt5_dim = self.igt5_model.config.d_model  # 512\n",
    "        self.esm2_dim = self.esm2_model.config.hidden_size  # 1280\n",
    "        self.combined_dim = self.igt5_dim + self.esm2_dim  # 1792\n",
    "        \n",
    "        print(f\"  üìè Embedding dimensions:\")\n",
    "        print(f\"     IgT5: {self.igt5_dim}D\")\n",
    "        print(f\"     ESM-2: {self.esm2_dim}D\")\n",
    "        print(f\"     Combined: {self.combined_dim}D\")\n",
    "        \n",
    "        # Build regression head: 1792 -> 1024 -> 512 -> 256 -> 128 -> 1\n",
    "        print(\"  üß† Building regression head...\")\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.combined_dim, 1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(1024),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(512),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(256),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(128),\n",
    "            \n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        frozen_params = total_params - trainable_params\n",
    "        \n",
    "        print(f\"\\n  üìä Model Statistics:\")\n",
    "        print(f\"     Total parameters: {total_params/1e6:.1f}M\")\n",
    "        print(f\"     Trainable parameters: {trainable_params/1e6:.1f}M\")\n",
    "        print(f\"     Frozen parameters: {frozen_params/1e6:.1f}M\")\n",
    "    \n",
    "    def forward(self, antibody_seqs, antigen_seqs, device):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            antibody_seqs: List of antibody sequences (strings)\n",
    "            antigen_seqs: List of antigen sequences (strings)\n",
    "            device: Device to run on (cuda/cpu)\n",
    "        \n",
    "        Returns:\n",
    "            Predicted pKd values (tensor, shape [batch_size])\n",
    "        \"\"\"\n",
    "        # Tokenize antibody sequences\n",
    "        antibody_tokens = self.igt5_tokenizer(\n",
    "            antibody_seqs,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "        \n",
    "        # Tokenize antigen sequences\n",
    "        antigen_tokens = self.esm2_tokenizer(\n",
    "            antigen_seqs,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024\n",
    "        ).to(device)\n",
    "        \n",
    "        # Encode antibody (mean pooling over sequence)\n",
    "        with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "            antibody_outputs = self.igt5_model(**antibody_tokens)\n",
    "            antibody_embedding = antibody_outputs.last_hidden_state.mean(dim=1)  # [batch, 512]\n",
    "            \n",
    "            # Encode antigen (mean pooling over sequence)\n",
    "            antigen_outputs = self.esm2_model(**antigen_tokens)\n",
    "            antigen_embedding = antigen_outputs.last_hidden_state.mean(dim=1)  # [batch, 1280]\n",
    "            \n",
    "            # Concatenate embeddings\n",
    "            combined = torch.cat([antibody_embedding, antigen_embedding], dim=1)  # [batch, 1792]\n",
    "            \n",
    "            # Regression head\n",
    "            pKd_pred = self.regression_head(combined).squeeze(-1)  # [batch]\n",
    "        \n",
    "        return pKd_pred\n",
    "\n",
    "print(\"‚úÖ Model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and move to GPU\n",
    "model = IgT5ESM2Model(\n",
    "    dropout=0.35,\n",
    "    freeze_encoders=True,\n",
    "    use_checkpointing=True\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\n‚úÖ Model built successfully!\")\n",
    "print(f\"‚úÖ Model moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Training Configuration\n",
    "\n",
    "**What this does:**\n",
    "- Sets all hyperparameters\n",
    "- Creates optimizer (AdamW with weight decay for L2 regularization)\n",
    "- Creates LR scheduler (warmup + cosine decay)\n",
    "- Creates loss function (Focal MSE + label smoothing)\n",
    "- Initializes early stopping\n",
    "\n",
    "**Why these choices:**\n",
    "- LR=3e-3: Fast convergence without instability\n",
    "- Weight decay=0.02: Strong regularization to prevent overfitting\n",
    "- Dropout=0.35: Good balance (not too aggressive)\n",
    "- Warmup=5 epochs: Stabilizes early training\n",
    "- Early stopping patience=10: Gives model time to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "config = {\n",
    "    'epochs': 50,\n",
    "    'batch_size': 16,\n",
    "    'lr': 3e-3,\n",
    "    'weight_decay': 0.02,           # L2 regularization\n",
    "    'dropout': 0.35,\n",
    "    'warmup_epochs': 5,\n",
    "    'early_stopping_patience': 10,\n",
    "    'label_smoothing': 0.05,        # Prevents overconfident predictions\n",
    "    'max_grad_norm': 1.0,           # Gradient clipping\n",
    "    'validation_frequency': 1       # Validate every N epochs\n",
    "}\n",
    "\n",
    "# Optimizer with L2 regularization (weight decay)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    fused=True  # Faster on newer GPUs\n",
    ")\n",
    "\n",
    "# LR Scheduler with warmup\n",
    "scheduler = get_warmup_cosine_scheduler(\n",
    "    optimizer,\n",
    "    warmup_epochs=config['warmup_epochs'],\n",
    "    total_epochs=config['epochs']\n",
    ")\n",
    "\n",
    "# Loss function with label smoothing\n",
    "criterion = FocalMSELoss(\n",
    "    gamma=2.0,\n",
    "    label_smoothing=config['label_smoothing']\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config['early_stopping_patience'],\n",
    "    min_delta=0.0001,\n",
    "    mode='max'  # Maximize Spearman correlation\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training configuration complete!\")\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Training Loop\n",
    "\n",
    "**What this does:**\n",
    "- Trains model for up to 50 epochs\n",
    "- Quick validation every epoch (on 5% of val set for speed)\n",
    "- Gradient clipping for stability\n",
    "- Early stopping to prevent overfitting\n",
    "- Saves best model to Google Drive\n",
    "\n",
    "**Expected runtime:**\n",
    "- Tesla T4: ~3 minutes per epoch ‚Üí ~1.5-2.5 hours total\n",
    "- V100: ~2 minutes per epoch ‚Üí ~1-1.5 hours total\n",
    "\n",
    "**What you'll see:**\n",
    "- Progress bar for each epoch\n",
    "- Training loss decreasing\n",
    "- Validation Spearman increasing (hopefully!)\n",
    "- \"‚úÖ Saved best model\" when new best is found\n",
    "- Early stopping message when training stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, loader, optimizer, criterion, device, epoch, max_grad_norm):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network\n",
    "        loader: Training data loader\n",
    "        optimizer: PyTorch optimizer\n",
    "        criterion: Loss function\n",
    "        device: cuda or cpu\n",
    "        epoch: Current epoch number\n",
    "        max_grad_norm: Gradient clipping threshold\n",
    "    \n",
    "    Returns:\n",
    "        Average training loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in pbar:\n",
    "        antibody_seqs = batch['antibody_seqs']\n",
    "        antigen_seqs = batch['antigen_seqs']\n",
    "        targets = batch['pKd'].to(device)\n",
    "        \n",
    "        # Forward pass with mixed precision (BFloat16)\n",
    "        with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "            predictions = model(antibody_seqs, antigen_seqs, device)\n",
    "            loss = criterion(predictions, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (prevents exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"‚úÖ Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def eval_model(model, loader, device, desc=\"Evaluating\"):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation or test set.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network\n",
    "        loader: Validation/test data loader\n",
    "        device: cuda or cpu\n",
    "        desc: Description for progress bar\n",
    "    \n",
    "    Returns:\n",
    "        metrics: Dictionary with 12 metrics\n",
    "        predictions: Numpy array of predictions\n",
    "        targets: Numpy array of true values\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in tqdm(loader, desc=desc):\n",
    "            antibody_seqs = batch['antibody_seqs']\n",
    "            antigen_seqs = batch['antigen_seqs']\n",
    "            batch_targets = batch['pKd'].to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "                batch_predictions = model(antibody_seqs, antigen_seqs, device)\n",
    "            \n",
    "            # Collect results\n",
    "            predictions.extend(batch_predictions.float().cpu().numpy())\n",
    "            targets.extend(batch_targets.float().cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # Compute all metrics\n",
    "    metrics = compute_comprehensive_metrics(targets, predictions)\n",
    "    return metrics, predictions, targets\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Model checkpoint path (saved to Google Drive)\n",
    "model_save_path = os.path.join(OUTPUT_DIR, 'best_model.pth')\n",
    "\n",
    "best_spearman = -1\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_spearman': [],\n",
    "    'val_recall': [],\n",
    "    'epoch': []\n",
    "}\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss = train_epoch(\n",
    "        model, train_loader, optimizer, criterion, device,\n",
    "        epoch, config['max_grad_norm']\n",
    "    )\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate every N epochs\n",
    "    if (epoch + 1) % config['validation_frequency'] == 0:\n",
    "        val_metrics, _, _ = eval_model(model, val_loader_quick, device, \"Quick Val\")\n",
    "        val_spearman = val_metrics['spearman']\n",
    "        val_recall = val_metrics['recall_pkd9']\n",
    "        \n",
    "        print(f\"Val Spearman: {val_spearman:.4f} | Recall@pKd‚â•9: {val_recall:.2f}%\")\n",
    "        \n",
    "        # Save best model to Google Drive\n",
    "        if val_spearman > best_spearman:\n",
    "            best_spearman = val_spearman\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_spearman': val_spearman,\n",
    "                'config': config\n",
    "            }, model_save_path)\n",
    "            print(f\"‚úÖ Saved best model to Drive: {model_save_path}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_spearman, epoch):\n",
    "            print(f\"\\n‚õî Stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        # Record history\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_spearman'].append(val_spearman)\n",
    "        training_history['val_recall'].append(val_recall)\n",
    "        training_history['epoch'].append(epoch + 1)\n",
    "    \n",
    "    # LR scheduler step\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING COMPLETE!\")\n",
    "print(f\"Best Validation Spearman: {best_spearman:.4f}\")\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Comprehensive Evaluation\n",
    "\n",
    "**What this does:**\n",
    "- Loads the best model from Google Drive\n",
    "- Evaluates on FULL validation set (100% of val data)\n",
    "- Evaluates on TEST set (100% of test data) - **This is your TRUE performance!**\n",
    "- Computes all 12 metrics for both sets\n",
    "- Saves predictions and metrics to Google Drive\n",
    "\n",
    "**Why this matters:**\n",
    "- During training we only validated on 5% (for speed)\n",
    "- Now we get the full, accurate assessment\n",
    "- Test set was completely unseen during training\n",
    "- Test performance is what you should report in papers\n",
    "\n",
    "**Expected results:**\n",
    "- Spearman: 0.40-0.45\n",
    "- RMSE: 1.2-1.4 pKd units\n",
    "- Recall@pKd‚â•9: 95-100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from Google Drive\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL COMPREHENSIVE EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nLoading best model from Drive: {model_save_path}\")\n",
    "checkpoint = torch.load(model_save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Loaded model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Best quick validation Spearman: {checkpoint['val_spearman']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on FULL validation set\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"Evaluating on FULL validation set ({len(val_dataset_full):,} samples)...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "val_metrics, val_preds, val_targets = eval_model(\n",
    "    model, val_loader_full, device, \"Full Validation\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä FULL VALIDATION METRICS:\")\n",
    "print(f\"  Samples: {val_metrics['n_samples']:,}\")\n",
    "print(f\"  Strong Binders (pKd‚â•9): {val_metrics['n_strong_binders']}\")\n",
    "print(f\"\\n  Regression Metrics:\")\n",
    "print(f\"    RMSE:        {val_metrics['rmse']:.4f}\")\n",
    "print(f\"    MAE:         {val_metrics['mae']:.4f}\")\n",
    "print(f\"    MSE:         {val_metrics['mse']:.4f}\")\n",
    "print(f\"    R¬≤:          {val_metrics['r2']:.4f}\")\n",
    "print(f\"\\n  Correlation Metrics:\")\n",
    "print(f\"    Spearman œÅ:  {val_metrics['spearman']:.4f} (p={val_metrics['spearman_p']:.2e})\")\n",
    "print(f\"    Pearson r:   {val_metrics['pearson']:.4f} (p={val_metrics['pearson_p']:.2e})\")\n",
    "print(f\"\\n  Classification Metrics (pKd‚â•9):\")\n",
    "print(f\"    Recall:      {val_metrics['recall_pkd9']:.2f}%\")\n",
    "print(f\"    Precision:   {val_metrics['precision_pkd9']:.2f}%\")\n",
    "print(f\"    F1-Score:    {val_metrics['f1_pkd9']:.2f}%\")\n",
    "print(f\"    Specificity: {val_metrics['specificity_pkd9']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on TEST set (UNSEEN DATA!)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"Evaluating on TEST set ({len(test_dataset):,} samples)...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "test_metrics, test_preds, test_targets = eval_model(\n",
    "    model, test_loader, device, \"Test Set\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä TEST SET METRICS (UNSEEN DATA):\")\n",
    "print(f\"  Samples: {test_metrics['n_samples']:,}\")\n",
    "print(f\"  Strong Binders (pKd‚â•9): {test_metrics['n_strong_binders']}\")\n",
    "print(f\"\\n  Regression Metrics:\")\n",
    "print(f\"    RMSE:        {test_metrics['rmse']:.4f}\")\n",
    "print(f\"    MAE:         {test_metrics['mae']:.4f}\")\n",
    "print(f\"    MSE:         {test_metrics['mse']:.4f}\")\n",
    "print(f\"    R¬≤:          {test_metrics['r2']:.4f}\")\n",
    "print(f\"\\n  Correlation Metrics:\")\n",
    "print(f\"    Spearman œÅ:  {test_metrics['spearman']:.4f} (p={test_metrics['spearman_p']:.2e})\")\n",
    "print(f\"    Pearson r:   {test_metrics['pearson']:.4f} (p={test_metrics['pearson_p']:.2e})\")\n",
    "print(f\"\\n  Classification Metrics (pKd‚â•9):\")\n",
    "print(f\"    Recall:      {test_metrics['recall_pkd9']:.2f}%\")\n",
    "print(f\"    Precision:   {test_metrics['precision_pkd9']:.2f}%\")\n",
    "print(f\"    F1-Score:    {test_metrics['f1_pkd9']:.2f}%\")\n",
    "print(f\"    Specificity: {test_metrics['specificity_pkd9']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions and metrics to Google Drive\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Saving results to Google Drive...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Validation predictions\n",
    "val_results = pd.DataFrame({\n",
    "    'true_pKd': val_targets,\n",
    "    'pred_pKd': val_preds,\n",
    "    'error': val_preds - val_targets,\n",
    "    'abs_error': np.abs(val_preds - val_targets)\n",
    "})\n",
    "val_pred_path = os.path.join(OUTPUT_DIR, 'val_predictions.csv')\n",
    "val_results.to_csv(val_pred_path, index=False)\n",
    "print(f\"‚úÖ Saved: {val_pred_path}\")\n",
    "\n",
    "# Test predictions\n",
    "test_results = pd.DataFrame({\n",
    "    'true_pKd': test_targets,\n",
    "    'pred_pKd': test_preds,\n",
    "    'error': test_preds - test_targets,\n",
    "    'abs_error': np.abs(test_preds - test_targets)\n",
    "})\n",
    "test_pred_path = os.path.join(OUTPUT_DIR, 'test_predictions.csv')\n",
    "test_results.to_csv(test_pred_path, index=False)\n",
    "print(f\"‚úÖ Saved: {test_pred_path}\")\n",
    "\n",
    "# Save all metrics to JSON\n",
    "all_metrics = {\n",
    "    'validation_full': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v\n",
    "                       for k, v in val_metrics.items()},\n",
    "    'test': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v\n",
    "            for k, v in test_metrics.items()},\n",
    "    'best_quick_val_spearman': float(best_spearman),\n",
    "    'config': config\n",
    "}\n",
    "\n",
    "metrics_path = os.path.join(OUTPUT_DIR, 'final_metrics.json')\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=2)\n",
    "print(f\"‚úÖ Saved: {metrics_path}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ EVALUATION COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìå KEY RESULTS:\")\n",
    "print(f\"  Validation Spearman: {val_metrics['spearman']:.4f}\")\n",
    "print(f\"  Test Spearman:       {test_metrics['spearman']:.4f} ‚Üê TRUE PERFORMANCE\")\n",
    "print(f\"  Test RMSE:           {test_metrics['rmse']:.4f}\")\n",
    "print(f\"  Test MAE:            {test_metrics['mae']:.4f}\")\n",
    "print(f\"  Test R¬≤:             {test_metrics['r2']:.4f}\")\n",
    "print(f\"  Test Recall@pKd‚â•9:   {test_metrics['recall_pkd9']:.2f}%\")\n",
    "print(f\"\\nüìÅ All results saved to: {OUTPUT_DIR}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Results Visualization\n",
    "\n",
    "**What this does:**\n",
    "- Plots training curves (loss, Spearman correlation over epochs)\n",
    "- Creates scatter plots (predictions vs actual values)\n",
    "- Shows error distribution histogram\n",
    "- Saves all plots to Google Drive\n",
    "\n",
    "**Why visualizations matter:**\n",
    "- See if model is learning (loss decreasing, Spearman increasing)\n",
    "- Identify issues (overfitting, underfitting)\n",
    "- Understand prediction quality\n",
    "- Communicate results effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training loss\n",
    "ax1 = axes[0]\n",
    "ax1.plot(training_history['epoch'], training_history['train_loss'], 'b-o', linewidth=2, markersize=4)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Training Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Spearman\n",
    "ax2 = axes[1]\n",
    "ax2.plot(training_history['epoch'], training_history['val_spearman'], 'g-o', linewidth=2, markersize=4)\n",
    "ax2.axhline(y=best_spearman, color='r', linestyle='--', linewidth=2, label=f'Best: {best_spearman:.4f}')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Validation Spearman', fontsize=12)\n",
    "ax2.set_title('Validation Spearman Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "curves_path = os.path.join(OUTPUT_DIR, 'training_curves.png')\n",
    "plt.savefig(curves_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Saved: {curves_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual scatter plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Validation set\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(val_targets, val_preds, alpha=0.3, s=10, color='blue')\n",
    "ax1.plot([4, 14], [4, 14], 'r--', linewidth=2, label='Perfect prediction')\n",
    "ax1.set_xlabel('True pKd', fontsize=12)\n",
    "ax1.set_ylabel('Predicted pKd', fontsize=12)\n",
    "ax1.set_title(f'Validation Set\\nSpearman: {val_metrics[\"spearman\"]:.4f}, RMSE: {val_metrics[\"rmse\"]:.4f}',\n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(4, 14)\n",
    "ax1.set_ylim(4, 14)\n",
    "\n",
    "# Test set\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(test_targets, test_preds, alpha=0.3, s=10, color='orange')\n",
    "ax2.plot([4, 14], [4, 14], 'r--', linewidth=2, label='Perfect prediction')\n",
    "ax2.set_xlabel('True pKd', fontsize=12)\n",
    "ax2.set_ylabel('Predicted pKd', fontsize=12)\n",
    "ax2.set_title(f'Test Set (UNSEEN DATA)\\nSpearman: {test_metrics[\"spearman\"]:.4f}, RMSE: {test_metrics[\"rmse\"]:.4f}',\n",
    "              fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(4, 14)\n",
    "ax2.set_ylim(4, 14)\n",
    "\n",
    "plt.tight_layout()\n",
    "scatter_path = os.path.join(OUTPUT_DIR, 'predictions_scatter.png')\n",
    "plt.savefig(scatter_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Saved: {scatter_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "test_errors = test_preds - test_targets\n",
    "ax.hist(test_errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero error')\n",
    "ax.axvline(x=np.mean(test_errors), color='g', linestyle='--', linewidth=2,\n",
    "           label=f'Mean error: {np.mean(test_errors):.4f}')\n",
    "ax.set_xlabel('Prediction Error (pKd units)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Test Set: Error Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "error_path = os.path.join(OUTPUT_DIR, 'error_distribution.png')\n",
    "plt.savefig(error_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Saved: {error_path}\")\n",
    "\n",
    "# Error statistics\n",
    "print(f\"\\nüìä Error Analysis:\")\n",
    "print(f\"   Mean error:    {np.mean(test_errors):.4f} pKd\")\n",
    "print(f\"   Std error:     {np.std(test_errors):.4f} pKd\")\n",
    "print(f\"   Median |error|: {np.median(np.abs(test_errors)):.4f} pKd\")\n",
    "print(f\"   95th %ile |error|: {np.percentile(np.abs(test_errors), 95):.4f} pKd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all output files\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL RESULTS SAVED TO GOOGLE DRIVE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  1. best_model.pth - Trained model weights (~3.5GB)\")\n",
    "print(\"  2. val_predictions.csv - Validation predictions\")\n",
    "print(\"  3. test_predictions.csv - Test predictions\")\n",
    "print(\"  4. final_metrics.json - All metrics\")\n",
    "print(\"  5. training_curves.png - Training visualization\")\n",
    "print(\"  6. predictions_scatter.png - Prediction plots\")\n",
    "print(\"  7. error_distribution.png - Error analysis\")\n",
    "\n",
    "print(\"\\n‚úÖ All files are saved in your Google Drive!\")\n",
    "print(\"   You can access them anytime at:\")\n",
    "print(f\"   {OUTPUT_DIR}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Training Complete!\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've successfully trained a state-of-the-art antibody-antigen binding prediction model!\n",
    "\n",
    "### What you accomplished:\n",
    "‚úÖ Trained dual-encoder model (IgT5 + ESM-2)  \n",
    "‚úÖ Implemented modern training practices (warmup, early stopping, regularization)  \n",
    "‚úÖ Evaluated on proper train/val/test splits  \n",
    "‚úÖ Computed comprehensive metrics (12 total)  \n",
    "‚úÖ Created publication-ready visualizations  \n",
    "‚úÖ Saved all results to Google Drive\n",
    "\n",
    "### Key Results:\n",
    "- **Test Spearman:** Your true, unbiased performance metric\n",
    "- **Test RMSE:** Prediction error in pKd units\n",
    "- **Test Recall@pKd‚â•9:** How well you identify strong binders\n",
    "\n",
    "### Your Results (Saved in Drive):\n",
    "All outputs are in: `Google Drive/AbAg_Training_02/training_output/`\n",
    "\n",
    "### Next Steps:\n",
    "1. Access results in your Google Drive\n",
    "2. Analyze error patterns in `test_predictions.csv`\n",
    "3. Try improving performance:\n",
    "   - Experiment with hyperparameters (LR, dropout, warmup)\n",
    "   - Train ensemble of models\n",
    "   - Add more data\n",
    "\n",
    "### Questions?\n",
    "Review the code comments - each function is documented with:\n",
    "- What it does\n",
    "- Why it matters\n",
    "- How it works\n",
    "\n",
    "---\n",
    "\n",
    "**Happy modeling! üß¨üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}