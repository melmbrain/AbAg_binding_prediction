{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IgT5 + ESM-2 Training - ULTRA SPEED v2.6 (SIMPLIFIED)\n",
    "\n",
    "**No file writing - just direct execution!**\n",
    "\n",
    "Expected: 12-20Ã— faster than baseline (~3-4 hours for 50 epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/AbAg_Training')\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check available storage\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Storage Check:\")\n",
    "!df -h /content/drive/MyDrive | grep -v Filesystem\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing dependencies...\")\n",
    "!pip install -q transformers pandas scipy scikit-learn tqdm sentencepiece faesm bitsandbytes accelerate\n",
    "print(\"âœ“ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLATION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ“ PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ“ BFloat16 supported: {torch.cuda.is_bf16_supported()}\")\n",
    "\n",
    "# Check FlashAttention\n",
    "try:\n",
    "    import faesm\n",
    "    print(\"\\nâœ“âœ“âœ“ FAESM: FlashAttention available!\")\n",
    "except ImportError:\n",
    "    print(\"\\nâš  FAESM not installed - will use PyTorch SDPA\")\n",
    "\n",
    "# Check BitsAndBytes\n",
    "try:\n",
    "    import bitsandbytes\n",
    "    print(\"âœ“âœ“âœ“ BitsAndBytes: INT8 quantization available!\")\n",
    "except ImportError:\n",
    "    print(\"âš  BitsAndBytes not installed - will use BFloat16 only\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready to train!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check if training script exists, if not upload it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('train_ultra_speed_v26.py'):\n",
    "    print(\"âœ“ Training script found!\")\n",
    "    !ls -lh train_ultra_speed_v26.py\n",
    "else:\n",
    "    print(\"âš  Training script not found!\")\n",
    "    print(\"\\nPlease upload train_ultra_speed_v26.py to your Google Drive at:\")\n",
    "    print(\"/content/drive/MyDrive/AbAg_Training/\")\n",
    "    print(\"\\nOr run this to upload from your computer:\")\n",
    "    print(\"from google.colab import files\")\n",
    "    print(\"uploaded = files.upload()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Start Training! ðŸš€\n",
    "\n",
    "**Expected**: ~3-4 hours for 50 epochs (12-20Ã— faster than baseline)\n",
    "\n",
    "The script auto-detects Colab and uses optimized settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training - auto-resumes from checkpoint if exists\n",
    "!python train_ultra_speed_v26.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Monitor Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "checkpoint_path = 'outputs_max_speed/checkpoint_latest.pth'\n",
    "if Path(checkpoint_path).exists():\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    print(f\"Epoch: {checkpoint['epoch'] + 1}/50\")\n",
    "    print(f\"Batch: {checkpoint['batch_idx'] + 1}\")\n",
    "    print(f\"Best Spearman: {checkpoint['best_val_spearman']:.4f}\")\n",
    "\n",
    "    elapsed = time.time() - checkpoint['timestamp']\n",
    "    print(f\"\\nLast saved: {elapsed/60:.1f} minutes ago\")\n",
    "else:\n",
    "    print(\"No checkpoint found yet - training just started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check Disk Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h / | grep -v Filesystem\n",
    "\n",
    "print(\"\\nDisk usage breakdown:\")\n",
    "!du -sh outputs_max_speed 2>/dev/null || echo \"No checkpoints yet\"\n",
    "!du -sh ~/.cache/huggingface 2>/dev/null || echo \"No HF cache\"\n",
    "\n",
    "print(\"\\nðŸ’¡ v2.6 auto-cleans when disk > 150GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
